{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd5bHF9Cw9m_"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 1: Install Dependencies\n",
        "# ==============================\n",
        "!pip install tensorflow --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS2neXOlxMHu"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 2: Import Libraries\n",
        "# ==============================\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from IPython.display import display\n",
        "from ipywidgets import FileUpload\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN-jxkzQxOqr"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 3: Download & Extract Dataset\n",
        "# ==============================\n",
        "DATASET_URL = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/mhjyrn35p4-2.zip\"\n",
        "ZIP_FILE = \"oral_images.zip\"\n",
        "DATASET_DIR = \"dataset\"\n",
        "\n",
        "def download_dataset():\n",
        "    if not os.path.exists(ZIP_FILE):\n",
        "        print(\"Downloading dataset...\")\n",
        "        r = requests.get(DATASET_URL, stream=True)\n",
        "        with open(ZIP_FILE, \"wb\") as f:\n",
        "            shutil.copyfileobj(r.raw, f)\n",
        "        print(\"Download complete.\")\n",
        "    else:\n",
        "        print(\"ZIP file already exists, skipping download.\")\n",
        "\n",
        "def extract_dataset():\n",
        "    if not os.path.exists(\"oral_images\"):\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"oral_images\")\n",
        "        print(\"Extraction complete.\")\n",
        "    else:\n",
        "        print(\" Dataset already extracted.\")\n",
        "\n",
        "download_dataset()\n",
        "extract_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeUSapNYxRD_"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 4: Organize Dataset\n",
        "# ==============================\n",
        "def create_folders():\n",
        "    for split in [\"train\", \"test\"]:\n",
        "        for cls in [\"Cancer\", \"Non-Cancer\"]:\n",
        "            os.makedirs(os.path.join(DATASET_DIR, split, cls), exist_ok=True)\n",
        "\n",
        "def move_images(src_dir, train_dir, test_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(src_dir) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "    random.shuffle(images)\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    for img in images[:split_idx]:\n",
        "        shutil.copy(os.path.join(src_dir, img), os.path.join(train_dir, img))\n",
        "    for img in images[split_idx:]:\n",
        "        shutil.copy(os.path.join(src_dir, img), os.path.join(test_dir, img))\n",
        "\n",
        "def split_dataset():\n",
        "    print(\" Organizing dataset into train/test...\")\n",
        "    benign_path, malignant_path = None, None\n",
        "    for root, dirs, files in os.walk(\"oral_images\"):\n",
        "        for d in dirs:\n",
        "            if \"Benign\" in d or \"benign\" in d:\n",
        "                benign_path = os.path.join(root, d)\n",
        "            elif \"Malignant\" in d or \"malignant\" in d:\n",
        "                malignant_path = os.path.join(root, d)\n",
        "    if not benign_path or not malignant_path:\n",
        "        raise Exception(\"Could not find Benign/Malignant folders in dataset.\")\n",
        "\n",
        "    move_images(benign_path, os.path.join(DATASET_DIR, \"train\", \"Non-Cancer\"),\n",
        "                os.path.join(DATASET_DIR, \"test\", \"Non-Cancer\"))\n",
        "    move_images(malignant_path, os.path.join(DATASET_DIR, \"train\", \"Cancer\"),\n",
        "                os.path.join(DATASET_DIR, \"test\", \"Cancer\"))\n",
        "    print(\" Dataset organized successfully.\")\n",
        "\n",
        "create_folders()\n",
        "split_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml7suMl4xTKg"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 5: Train DenseNet169 Model\n",
        "# ==============================\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_DIR, \"train\"),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_DIR, \"test\"),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Base model\n",
        "base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "checkpoint = ModelCheckpoint(\"model/densenet169_binary_classifier.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sodgz-wLxYUj"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Module 6: Save & Download Model\n",
        "# ==============================\n",
        "model.save(\"final_densenet169_model.h5\")\n",
        "print(\"Model saved as final_densenet169_model.h5\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"final_densenet169_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DhPSjhftrNs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load model once\n",
        "model = load_model(\"final_densenet169_model.h5\")\n",
        "\n",
        "# Get expected input shape (e.g., 128x128x3)\n",
        "input_shape = model.input_shape[1:3]  # (height, width)\n",
        "\n",
        "# Upload widget\n",
        "upload = FileUpload(accept='image/*', multiple=False)\n",
        "display(upload)\n",
        "\n",
        "def handle_upload(change):\n",
        "    for name, file_info in upload.value.items():\n",
        "        # Resize to match model input\n",
        "        img = Image.open(io.BytesIO(file_info['content'])).resize(input_shape)\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array /= 255.0\n",
        "\n",
        "        # Predict\n",
        "        prediction = model.predict(img_array)[0][0]  # Extract scalar value\n",
        "\n",
        "        # Decode label\n",
        "        label = \"NonCancerous\" if prediction >= 0.5 else \"Cancerous\"\n",
        "        confidence = round(prediction * 100, 2) if prediction >= 0.5 else round((1 - prediction) * 100, 2)\n",
        "\n",
        "        # Output\n",
        "        print(f\"Prediction: {label}\")\n",
        "        print(f\"Confidence: {confidence}%\")\n",
        "\n",
        "# Trigger prediction when file is uploaded\n",
        "upload.observe(handle_upload, names='value')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP060xfgePQUvHhVe0/OH3k"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}